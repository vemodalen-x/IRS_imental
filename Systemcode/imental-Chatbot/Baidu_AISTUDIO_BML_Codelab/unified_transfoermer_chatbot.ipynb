{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b4d76f-196b-4406-8173-08c21eb58a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:56:11.747985Z",
     "iopub.status.busy": "2021-10-24T07:56:11.747658Z",
     "iopub.status.idle": "2021-10-24T07:56:19.940197Z",
     "shell.execute_reply": "2021-10-24T07:56:19.939395Z",
     "shell.execute_reply.started": "2021-10-24T07:56:11.747834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-24 15:56:13,520] [    INFO] - Found /home/aistudio/.paddlenlp/models/plato-mini/plato-mini-vocab.txt\n",
      "[2021-10-24 15:56:13,523] [    INFO] - Found /home/aistudio/.paddlenlp/models/plato-mini/plato-mini-spm.model\n",
      "[2021-10-24 15:56:13,588] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/plato-mini/plato-mini.pdparams\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import UnifiedTransformerTokenizer\r\n",
    "from paddlenlp.transformers import UnifiedTransformerLMHeadModel\r\n",
    "\r\n",
    "# set model 'unified_transformer-12L-cn' 'unified_transformer-12L-cn-luge' 'plato-mini'\r\n",
    "model_name = 'plato-mini'\r\n",
    "tokenizer = UnifiedTransformerTokenizer.from_pretrained(model_name)\r\n",
    "model = UnifiedTransformerLMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a25422a-7a1e-4a5f-a1d9-965ad3862840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:56:20.065977Z",
     "iopub.status.busy": "2021-10-24T07:56:20.065790Z",
     "iopub.status.idle": "2021-10-24T07:56:21.389232Z",
     "shell.execute_reply": "2021-10-24T07:56:21.388568Z",
     "shell.execute_reply.started": "2021-10-24T07:56:20.065943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.655 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'position_ids', 'attention_mask'])\n",
      "Tensor(shape=[31], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [912, 28 , 3  , 6  , 763, 1164, 26028, 3  , 9  , 42 , 25375, 7  , 28 , 16 , 2  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  , 0  ])\n",
      "Tensor(shape=[1], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [-0.80845112])\n"
     ]
    }
   ],
   "source": [
    "user_input = ['你好啊，你今年多大了']\r\n",
    "\r\n",
    "# dialogue_encode as input\r\n",
    "encoded_input = tokenizer.dialogue_encode(\r\n",
    "                    user_input,\r\n",
    "                    add_start_token_as_response=True,\r\n",
    "                    return_tensors=True,\r\n",
    "                    is_split_into_words=False)\r\n",
    "print(encoded_input.keys())\r\n",
    "ids, scores = model.generate(\r\n",
    "                input_ids=encoded_input['input_ids'],\r\n",
    "                token_type_ids=encoded_input['token_type_ids'],\r\n",
    "                position_ids=encoded_input['position_ids'],\r\n",
    "                attention_mask=encoded_input['attention_mask'],\r\n",
    "                max_length=64,\r\n",
    "                min_length=1,\r\n",
    "                decode_strategy='sampling',\r\n",
    "                top_k=5,\r\n",
    "                num_return_sequences=20)\r\n",
    "\r\n",
    "print(ids[0])\r\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9efad57-be83-4e21-9838-28dec3cd407d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:56:31.854995Z",
     "iopub.status.busy": "2021-10-24T07:56:31.854648Z",
     "iopub.status.idle": "2021-10-24T07:56:31.864726Z",
     "shell.execute_reply": "2021-10-24T07:56:31.864029Z",
     "shell.execute_reply.started": "2021-10-24T07:56:31.854939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你好啊,我今年23岁,你多大了啊?']\n"
     ]
    }
   ],
   "source": [
    "from utils import select_response\r\n",
    "\r\n",
    "# select the best answer\r\n",
    "result = select_response(ids, scores, tokenizer, keep_space=False, num_return_sequences=20)\r\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
