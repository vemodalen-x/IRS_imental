{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376a70e3-9971-4157-9a00-fed5cccd5789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:37:44.115008Z",
     "iopub.status.busy": "2021-10-24T07:37:44.114796Z",
     "iopub.status.idle": "2021-10-24T07:37:49.834737Z",
     "shell.execute_reply": "2021-10-24T07:37:49.833994Z",
     "shell.execute_reply.started": "2021-10-24T07:37:44.114969Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-24 15:37:45,862] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill/gpt-cpm-small-cn-distill.pdparams\n",
      "[2021-10-24 15:37:49,433] [    INFO] - Weights of GPTLMHeadModel not initialized from pretrained model: ['lm_head.decoder_weight']\n",
      "[2021-10-24 15:37:49,786] [    INFO] - Found /home/aistudio/.paddlenlp/models/gpt-cpm-small-cn-distill/gpt-cpm-cn-sentencepiece.model\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import GPTChineseTokenizer\r\n",
    "from paddlenlp.transformers import GPTLMHeadModel\r\n",
    "\r\n",
    "# set chinese token model\r\n",
    "model_name = 'gpt-cpm-small-cn-distill'\r\n",
    "model = GPTLMHeadModel.from_pretrained(model_name)\r\n",
    "tokenizer = GPTChineseTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23319834-830f-4191-86a8-26b0c5834455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:45:47.205574Z",
     "iopub.status.busy": "2021-10-24T07:45:47.205220Z",
     "iopub.status.idle": "2021-10-24T07:45:47.213722Z",
     "shell.execute_reply": "2021-10-24T07:45:47.213107Z",
     "shell.execute_reply.started": "2021-10-24T07:45:47.205526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 530, 44, 5263]\n",
      "Tensor(shape=[1, 4], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[44  , 530 , 44  , 5263]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "user_input = \"一加一等于\" #chinese input\r\n",
    "\r\n",
    "# text to ids\r\n",
    "input_ids = tokenizer(user_input)['input_ids']\r\n",
    "print(input_ids)\r\n",
    "\r\n",
    "# id2tensor\r\n",
    "input_ids = paddle.to_tensor(input_ids, dtype='int64').unsqueeze(0)\r\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5108ff46-6b4b-4cc1-95d6-c8e9956f7225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-24T07:45:49.213605Z",
     "iopub.status.busy": "2021-10-24T07:45:49.213233Z",
     "iopub.status.idle": "2021-10-24T07:45:49.649046Z",
     "shell.execute_reply": "2021-10-24T07:45:49.648317Z",
     "shell.execute_reply.started": "2021-10-24T07:45:49.213560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二,二加一等于三,三加一等于四\n"
     ]
    }
   ],
   "source": [
    "# chiese GPT model\r\n",
    "ids, scores = model.generate(\r\n",
    "                input_ids=input_ids,\r\n",
    "                max_length=16,\r\n",
    "                min_length=1,\r\n",
    "                decode_strategy='greedy_search')\r\n",
    "\r\n",
    "generated_ids = ids[0].numpy().tolist()\r\n",
    "\r\n",
    "# id2text\r\n",
    "generated_text = tokenizer.convert_ids_to_string(generated_ids)\r\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
