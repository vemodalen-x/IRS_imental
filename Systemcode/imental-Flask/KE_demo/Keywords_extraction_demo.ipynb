{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b78314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=81b4977fe573c6bd3cae9b8cceb8d08feba234827552615af4fdbf85e5e5295c\n",
      "  Stored in directory: c:\\users\\wang\\appdata\\local\\pip\\cache\\wheels\\ca\\38\\d8\\dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3059c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952f8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def keyword_extract(path):\n",
    "    file = open(path,\"rb\")\n",
    "    sent = file.read()\n",
    "\n",
    "    print('TF-IDF')\n",
    "    t = jieba.analyse.TFIDF()\n",
    "    kws = t.extract_tags(sent,topK=10, withWeight=True,allowPOS=('ns','n','vn','v','a'))\n",
    "    word_list = []\n",
    "    for word,weight in kws:\n",
    "        #print(\"%s\"%(word))\n",
    "        word_list.append(word)\n",
    "        print(\"%s %.4f\"%(word,weight))\n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f36aac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Wang\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.330 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关系 0.2611\n",
      "亲密关系 0.1964\n",
      "过渡期 0.1749\n",
      "对方 0.1683\n",
      "伴侣 0.1181\n",
      "热恋 0.0985\n",
      "付出 0.0726\n",
      "可能 0.0705\n",
      "满意度 0.0610\n",
      "沟通 0.0610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['关系', '亲密关系', '过渡期', '对方', '伴侣', '热恋', '付出', '可能', '满意度', '沟通']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list1 = keyword_extract(\"test.txt\")\n",
    "word_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e03bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "敏感 0.6737\n",
      "情绪 0.1561\n",
      "高度 0.1395\n",
      "敏感度 0.1280\n",
      "人群 0.1263\n",
      "能够 0.0887\n",
      "觉察 0.0807\n",
      "发现 0.0733\n",
      "人们 0.0664\n",
      "误解 0.0646\n"
     ]
    }
   ],
   "source": [
    "word_list2 = keyword_extract(\"test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f25186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "创伤 0.3851\n",
      "代际 0.1672\n",
      "父母 0.1649\n",
      "孩子 0.1176\n",
      "经历 0.1171\n",
      "传递 0.0974\n",
      "一代人 0.0881\n",
      "事件 0.0847\n",
      "比如 0.0780\n",
      "过度 0.0779\n"
     ]
    }
   ],
   "source": [
    "word_list3 = keyword_extract(\"test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54146383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "焦虑 0.3304\n",
      "吵闹 0.1610\n",
      "能够 0.1578\n",
      "体验 0.0994\n",
      "状态 0.0747\n",
      "感到 0.0703\n",
      "不同 0.0583\n",
      "成长 0.0571\n",
      "过度 0.0533\n",
      "负面 0.0529\n"
     ]
    }
   ],
   "source": [
    "word_list4 = keyword_extract(\"test3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5d4e43-4002-41b4-953b-5b1189c9ba40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "伴侣 0.4418\n",
      "冲突 0.3770\n",
      "亲密关系 0.1908\n",
      "应对 0.1648\n",
      "建设性 0.1092\n",
      "方式 0.1064\n",
      "负面 0.1013\n",
      "人们 0.0958\n",
      "回应 0.0889\n",
      "沟通 0.0770\n"
     ]
    }
   ],
   "source": [
    "word_list5 = keyword_extract(\"test4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0648574-8ac7-445b-9bee-5bf99fcf58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "伴侣 1.0349\n",
      "信任 0.4090\n",
      "亲密关系 0.1423\n",
      "信念 0.1286\n",
      "对方 0.1129\n",
      "相信 0.0785\n",
      "暴露 0.0760\n",
      "行为 0.0747\n",
      "预判 0.0691\n",
      "冲突 0.0660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['伴侣', '信任', '亲密关系', '信念', '对方', '相信', '暴露', '行为', '预判', '冲突']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list6 = keyword_extract(\"test5.txt\")\n",
    "word_list6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb536663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "article1=''\n",
    "for item in word_list1:\n",
    "    article1 = article1 + item\n",
    "article2=''\n",
    "for item in word_list2:\n",
    "    article2 = article2 + item\n",
    "article3=''\n",
    "for item in word_list3:\n",
    "    article3 = article3 + item\n",
    "article4=''\n",
    "for item in word_list4:\n",
    "    article4 = article4 + item\n",
    "article5=''\n",
    "for item in word_list5:\n",
    "    article5 = article5 + item\n",
    "article6=''\n",
    "for item in word_list6:\n",
    "    article6 = article6 + item\n",
    "\n",
    "article_list = []\n",
    "article_list.append(article1)\n",
    "article_list.append(article2)\n",
    "article_list.append(article3)\n",
    "article_list.append(article4)\n",
    "article_list.append(article5)\n",
    "article_list.append(article6)\n",
    "#list_1 = sum(word_list4,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62f30cb-9bb3-4b03-95eb-65c3b6b0208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['关系亲密关系过渡期对方伴侣热恋付出可能满意度沟通',\n",
       " '敏感情绪高度敏感度人群能够觉察发现人们误解',\n",
       " '创伤代际父母孩子经历传递一代人事件比如过度',\n",
       " '焦虑吵闹能够体验状态感到不同成长过度负面',\n",
       " '伴侣冲突亲密关系应对建设性方式负面人们回应沟通',\n",
       " '伴侣信任亲密关系信念对方相信暴露行为预判冲突']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbd9588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w2v.baidu_encyclopedia.target.word-word.dim300', 'w2v.baidu_encyclopedia.target.word-character.char1-1.dim300', 'w2v.baidu_encyclopedia.target.word-character.char1-2.dim300', 'w2v.baidu_encyclopedia.target.word-character.char1-4.dim300', 'w2v.baidu_encyclopedia.target.word-ngram.1-2.dim300', 'w2v.baidu_encyclopedia.target.word-ngram.1-3.dim300', 'w2v.baidu_encyclopedia.target.word-ngram.2-2.dim300', 'w2v.baidu_encyclopedia.target.word-wordLR.dim300', 'w2v.baidu_encyclopedia.target.word-wordPosition.dim300', 'w2v.baidu_encyclopedia.target.bigram-char.dim300', 'w2v.baidu_encyclopedia.context.word-word.dim300', 'w2v.baidu_encyclopedia.context.word-character.char1-1.dim300', 'w2v.baidu_encyclopedia.context.word-character.char1-2.dim300', 'w2v.baidu_encyclopedia.context.word-character.char1-4.dim300', 'w2v.baidu_encyclopedia.context.word-ngram.1-2.dim300', 'w2v.baidu_encyclopedia.context.word-ngram.1-3.dim300', 'w2v.baidu_encyclopedia.context.word-ngram.2-2.dim300', 'w2v.baidu_encyclopedia.context.word-wordLR.dim300', 'w2v.baidu_encyclopedia.context.word-wordPosition.dim300', 'w2v.wiki.target.bigram-char.dim300', 'w2v.wiki.target.word-char.dim300', 'w2v.wiki.target.word-word.dim300', 'w2v.wiki.target.word-bigram.dim300', 'w2v.people_daily.target.bigram-char.dim300', 'w2v.people_daily.target.word-char.dim300', 'w2v.people_daily.target.word-word.dim300', 'w2v.people_daily.target.word-bigram.dim300', 'w2v.weibo.target.bigram-char.dim300', 'w2v.weibo.target.word-char.dim300', 'w2v.weibo.target.word-word.dim300', 'w2v.weibo.target.word-bigram.dim300', 'w2v.sogou.target.bigram-char.dim300', 'w2v.sogou.target.word-char.dim300', 'w2v.sogou.target.word-word.dim300', 'w2v.sogou.target.word-bigram.dim300', 'w2v.zhihu.target.bigram-char.dim300', 'w2v.zhihu.target.word-char.dim300', 'w2v.zhihu.target.word-word.dim300', 'w2v.zhihu.target.word-bigram.dim300', 'w2v.financial.target.bigram-char.dim300', 'w2v.financial.target.word-char.dim300', 'w2v.financial.target.word-word.dim300', 'w2v.financial.target.word-bigram.dim300', 'w2v.literature.target.bigram-char.dim300', 'w2v.literature.target.word-char.dim300', 'w2v.literature.target.word-word.dim300', 'w2v.literature.target.word-bigram.dim300', 'w2v.sikuquanshu.target.word-word.dim300', 'w2v.sikuquanshu.target.word-bigram.dim300', 'w2v.mixed-large.target.word-char.dim300', 'w2v.mixed-large.target.word-word.dim300', 'w2v.google_news.target.word-word.dim300.en', 'glove.wiki2014-gigaword.target.word-word.dim50.en', 'glove.wiki2014-gigaword.target.word-word.dim100.en', 'glove.wiki2014-gigaword.target.word-word.dim200.en', 'glove.wiki2014-gigaword.target.word-word.dim300.en', 'glove.twitter.target.word-word.dim25.en', 'glove.twitter.target.word-word.dim50.en', 'glove.twitter.target.word-word.dim100.en', 'glove.twitter.target.word-word.dim200.en', 'fasttext.wiki-news.target.word-word.dim300.en', 'fasttext.crawl.target.word-word.dim300.en']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-28 16:00:13,296] [    INFO] - Loading token embedding...\n",
      "[2021-10-28 16:00:25,022] [    INFO] - Finish loading embedding vector.\n",
      "[2021-10-28 16:00:25,022] [    INFO] - Token Embedding info:             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Shape :[635965, 300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object   type: TokenEmbedding(635965, 300, padding_idx=635964, sparse=False)             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Parameter containing:\n",
      "Tensor(shape=[635965, 300], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-0.24200200,  0.13931701,  0.07378800, ...,  0.14103900,  0.05592300, -0.08004800],\n",
      "        [-0.08671700,  0.07770800,  0.09515300, ...,  0.11196400,  0.03082200, -0.12893000],\n",
      "        [-0.11436500,  0.12201900,  0.02833000, ...,  0.11068700,  0.03607300, -0.13763499],\n",
      "        ...,\n",
      "        [ 0.02628800, -0.00008300, -0.00393500, ...,  0.00654000,  0.00024600, -0.00662600],\n",
      "        [-0.00266621,  0.00262314,  0.02333385, ..., -0.00113022,  0.01450195,  0.02582437],\n",
      "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,  0.        ,  0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddlenlp.embeddings import TokenEmbedding, list_embedding_name\n",
    "paddle.set_device(\"gpu\")\n",
    "\n",
    "print(list_embedding_name()) # ['w2v.baidu_encyclopedia.target.word-word.dim300']\n",
    "token_embedding = TokenEmbedding(embedding_name=\"w2v.baidu_encyclopedia.target.word-word.dim300\")\n",
    "print(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec6ba561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0.345146644115448, {'亲密关系': 0.41248652, '热恋': 0.3554591, '可能': 0.32720622, '满意度': 0.32137865, '沟通': 0.30920273})\n",
      "2 (0.4570730566978455, {'情绪': 0.69757235, '觉察': 0.40841025, '敏感': 0.39597133, '人群': 0.39422742, '误解': 0.38918394})\n",
      "3 (0.38344801068305967, {'孩子': 0.4247513, '创伤': 0.39788967, '过度': 0.39754805, '父母': 0.35261762, '代际': 0.3444334})\n",
      "4 (0.5477967083454132, {'焦虑': 1.0000001, '感到': 0.4842094, '负面': 0.46975103, '过度': 0.39754805, '状态': 0.38747495})\n",
      "5 (0.40388732552528384, {'负面': 0.46975103, '冲突': 0.43605098, '亲密关系': 0.41248652, '应对': 0.3693148, '建设性': 0.3318333})\n",
      "6 (0.38380764722824096, {'冲突': 0.43605098, '亲密关系': 0.41248652, '行为': 0.37238505, '信念': 0.3701144, '预判': 0.3280013})\n"
     ]
    }
   ],
   "source": [
    "#test_token_embedding = token_embedding.search(\"焦虑\")\n",
    "from collections import Counter\n",
    "\n",
    "def get_order_dict_N(_dict, N):\n",
    "    result = Counter(_dict).most_common(N)\n",
    "    d = {}\n",
    "    average = 0\n",
    "    for k,v in result:\n",
    "        d[k] = v\n",
    "        average = average + v\n",
    "    return average/N,d\n",
    "\n",
    "# txt_list=['中国人','美国汽车','中国','中国是一个国家','你好']\n",
    "\n",
    "\n",
    "def search_list(input_txt,target_list,method='cosine',topk=5):\n",
    "    dic={}\n",
    "    score=[]\n",
    "    for txt in target_list:\n",
    "        dic[txt]=token_embedding.cosine_sim(input_txt, txt)  \n",
    "    return get_order_dict_N(dic,topk)\n",
    "\n",
    "print(1,search_list('焦虑',word_list1,method='cosine',topk=5))\n",
    "print(2,search_list('焦虑',word_list2,method='cosine',topk=5))\n",
    "print(3,search_list('焦虑',word_list3,method='cosine',topk=5))\n",
    "print(4,search_list('焦虑',word_list4,method='cosine',topk=5))\n",
    "print(5,search_list('焦虑',word_list5,method='cosine',topk=5))\n",
    "print(6,search_list('焦虑',word_list6,method='cosine',topk=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e0d53-0a94-41ea-8f2d-b3d2f3b804c5",
   "metadata": {},
   "source": [
    "So the rank is 4,2,5,6,3,1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
